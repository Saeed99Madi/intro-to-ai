{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Genetic Algorithms and Evolutionary Computation\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- Understand evolutionary computation principles\n",
    "- Implement genetic algorithms from scratch\n",
    "- Design encoding schemes for different problems\n",
    "- Apply selection, crossover, and mutation operators\n",
    "- Tune GA parameters for optimal performance\n",
    "- Solve complex optimization problems with GAs\n",
    "\n",
    "## What are Genetic Algorithms?\n",
    "\n",
    "**Genetic Algorithms (GAs)** are inspired by biological evolution:\n",
    "- **Population**: Set of candidate solutions\n",
    "- **Fitness**: Quality measure for each solution\n",
    "- **Selection**: Better solutions more likely to reproduce\n",
    "- **Crossover**: Combine parents to create offspring\n",
    "- **Mutation**: Random changes for diversity\n",
    "\n",
    "**Key Idea**: \"Survival of the fittest\" leads to better solutions over generations!\n",
    "\n",
    "## Why Genetic Algorithms?\n",
    "\n",
    "**Advantages**:\n",
    "- Work on complex, non-differentiable problems\n",
    "- Explore multiple solutions in parallel\n",
    "- Handle discrete and continuous variables\n",
    "- Escape local optima naturally\n",
    "- No gradient information needed\n",
    "\n",
    "**Trade-offs**:\n",
    "- More evaluations than gradient methods\n",
    "- Many parameters to tune\n",
    "- No guarantee of optimality\n",
    "\n",
    "## Real-World Applications\n",
    "\n",
    "- ðŸ§¬ **Drug Design**: Molecular optimization\n",
    "- ðŸŽ¨ **Design**: Architecture, circuit layout\n",
    "- ðŸ¤– **Robotics**: Controller evolution\n",
    "- ðŸ“Š **Finance**: Portfolio optimization\n",
    "- ðŸŽ® **Game AI**: Strategy evolution\n",
    "- ðŸ§  **Neural Architecture Search**: AutoML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Callable, Optional\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Genetic Algorithm\n",
    "\n",
    "### GA Components\n",
    "\n",
    "1. **Representation**: How to encode solutions (binary, real-valued, permutation)\n",
    "2. **Fitness Function**: How to evaluate solution quality\n",
    "3. **Selection**: How to choose parents (tournament, roulette wheel)\n",
    "4. **Crossover**: How to combine parents (one-point, two-point, uniform)\n",
    "5. **Mutation**: How to introduce variation (bit flip, gaussian)\n",
    "\n",
    "### Basic GA Algorithm\n",
    "\n",
    "```\n",
    "1. Initialize population randomly\n",
    "2. Evaluate fitness of each individual\n",
    "3. While not converged:\n",
    "   a. Select parents based on fitness\n",
    "   b. Create offspring via crossover\n",
    "   c. Mutate offspring\n",
    "   d. Evaluate offspring fitness\n",
    "   e. Replace population (generational or steady-state)\n",
    "4. Return best solution\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm:\n",
    "    \"\"\"Basic Genetic Algorithm implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 fitness_fn: Callable,\n",
    "                 chromosome_length: int,\n",
    "                 population_size: int = 100,\n",
    "                 mutation_rate: float = 0.01,\n",
    "                 crossover_rate: float = 0.8,\n",
    "                 maximize: bool = True):\n",
    "        \"\"\"\n",
    "        Initialize Genetic Algorithm.\n",
    "        \n",
    "        Args:\n",
    "            fitness_fn: Function to evaluate fitness\n",
    "            chromosome_length: Length of binary chromosome\n",
    "            population_size: Number of individuals\n",
    "            mutation_rate: Probability of bit flip\n",
    "            crossover_rate: Probability of crossover\n",
    "            maximize: If True, maximize fitness; else minimize\n",
    "        \"\"\"\n",
    "        self.fitness_fn = fitness_fn\n",
    "        self.chromosome_length = chromosome_length\n",
    "        self.population_size = population_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.maximize = maximize\n",
    "        \n",
    "        self.population = []\n",
    "        self.fitness_history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Create random initial population.\"\"\"\n",
    "        self.population = [\n",
    "            np.random.randint(0, 2, self.chromosome_length)\n",
    "            for _ in range(self.population_size)\n",
    "        ]\n",
    "    \n",
    "    def evaluate_population(self) -> List[float]:\n",
    "        \"\"\"Evaluate fitness of all individuals.\"\"\"\n",
    "        return [self.fitness_fn(ind) for ind in self.population]\n",
    "    \n",
    "    def tournament_selection(self, fitness_values: List[float], \n",
    "                           tournament_size: int = 3) -> np.ndarray:\n",
    "        \"\"\"Select individual using tournament selection.\"\"\"\n",
    "        # Randomly select tournament_size individuals\n",
    "        tournament_indices = random.sample(range(len(self.population)), \n",
    "                                          tournament_size)\n",
    "        tournament_fitness = [fitness_values[i] for i in tournament_indices]\n",
    "        \n",
    "        # Select best (or worst if minimizing)\n",
    "        if self.maximize:\n",
    "            winner_idx = tournament_indices[np.argmax(tournament_fitness)]\n",
    "        else:\n",
    "            winner_idx = tournament_indices[np.argmin(tournament_fitness)]\n",
    "        \n",
    "        return self.population[winner_idx].copy()\n",
    "    \n",
    "    def one_point_crossover(self, parent1: np.ndarray, \n",
    "                           parent2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"One-point crossover.\"\"\"\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "        \n",
    "        # Choose crossover point\n",
    "        point = random.randint(1, self.chromosome_length - 1)\n",
    "        \n",
    "        # Create offspring\n",
    "        offspring1 = np.concatenate([parent1[:point], parent2[point:]])\n",
    "        offspring2 = np.concatenate([parent2[:point], parent1[point:]])\n",
    "        \n",
    "        return offspring1, offspring2\n",
    "    \n",
    "    def mutate(self, individual: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Bit-flip mutation.\"\"\"\n",
    "        mutated = individual.copy()\n",
    "        for i in range(len(mutated)):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mutated[i] = 1 - mutated[i]  # Flip bit\n",
    "        return mutated\n",
    "    \n",
    "    def evolve(self, generations: int = 100) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"Run genetic algorithm for specified generations.\"\"\"\n",
    "        self.initialize_population()\n",
    "        self.fitness_history = []\n",
    "        \n",
    "        for generation in range(generations):\n",
    "            # Evaluate fitness\n",
    "            fitness_values = self.evaluate_population()\n",
    "            \n",
    "            # Track best fitness\n",
    "            if self.maximize:\n",
    "                best_fitness = max(fitness_values)\n",
    "                best_idx = np.argmax(fitness_values)\n",
    "            else:\n",
    "                best_fitness = min(fitness_values)\n",
    "                best_idx = np.argmin(fitness_values)\n",
    "            \n",
    "            self.fitness_history.append(best_fitness)\n",
    "            \n",
    "            # Create new population\n",
    "            new_population = []\n",
    "            \n",
    "            # Elitism: keep best individual\n",
    "            new_population.append(self.population[best_idx].copy())\n",
    "            \n",
    "            # Generate rest of population\n",
    "            while len(new_population) < self.population_size:\n",
    "                # Selection\n",
    "                parent1 = self.tournament_selection(fitness_values)\n",
    "                parent2 = self.tournament_selection(fitness_values)\n",
    "                \n",
    "                # Crossover\n",
    "                offspring1, offspring2 = self.one_point_crossover(parent1, parent2)\n",
    "                \n",
    "                # Mutation\n",
    "                offspring1 = self.mutate(offspring1)\n",
    "                offspring2 = self.mutate(offspring2)\n",
    "                \n",
    "                new_population.extend([offspring1, offspring2])\n",
    "            \n",
    "            # Trim to population size\n",
    "            self.population = new_population[:self.population_size]\n",
    "        \n",
    "        # Return best solution\n",
    "        final_fitness = self.evaluate_population()\n",
    "        if self.maximize:\n",
    "            best_idx = np.argmax(final_fitness)\n",
    "        else:\n",
    "            best_idx = np.argmin(final_fitness)\n",
    "        \n",
    "        return self.population[best_idx], final_fitness[best_idx]\n",
    "\n",
    "\n",
    "# Example: Maximize number of ones (OneMax problem)\n",
    "def onemax_fitness(chromosome: np.ndarray) -> float:\n",
    "    \"\"\"Fitness = number of 1s in chromosome.\"\"\"\n",
    "    return np.sum(chromosome)\n",
    "\n",
    "print(\"OneMax Problem: Maximize number of 1s\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "ga = GeneticAlgorithm(\n",
    "    fitness_fn=onemax_fitness,\n",
    "    chromosome_length=50,\n",
    "    population_size=100,\n",
    "    mutation_rate=0.01,\n",
    "    crossover_rate=0.8,\n",
    "    maximize=True\n",
    ")\n",
    "\n",
    "best_solution, best_fitness = ga.evolve(generations=100)\n",
    "\n",
    "print(f\"Best solution: {''.join(map(str, best_solution[:20]))}... (showing first 20 bits)\")\n",
    "print(f\"Best fitness: {best_fitness}/{len(best_solution)}\")\n",
    "print(f\"Percentage of 1s: {best_fitness/len(best_solution)*100:.1f}%\")\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ga.fitness_history, linewidth=2, color='blue')\n",
    "plt.axhline(y=len(best_solution), color='r', linestyle='--', \n",
    "           label='Optimal', linewidth=2)\n",
    "plt.xlabel('Generation', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('Best Fitness', fontweight='bold', fontsize=12)\n",
    "plt.title('GA Convergence on OneMax Problem', fontweight='bold', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Real-Valued Genetic Algorithm\n",
    "\n",
    "For continuous optimization, we use real-valued chromosomes instead of binary.\n",
    "\n",
    "### Operators for Real-Valued GAs\n",
    "\n",
    "**Crossover**:\n",
    "- Blend crossover (BLX-Î±)\n",
    "- Simulated binary crossover (SBX)\n",
    "\n",
    "**Mutation**:\n",
    "- Gaussian mutation\n",
    "- Polynomial mutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealValuedGA:\n",
    "    \"\"\"Genetic Algorithm for continuous optimization.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 fitness_fn: Callable,\n",
    "                 bounds: List[Tuple[float, float]],\n",
    "                 population_size: int = 100,\n",
    "                 mutation_rate: float = 0.1,\n",
    "                 crossover_rate: float = 0.8,\n",
    "                 maximize: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize Real-Valued GA.\n",
    "        \n",
    "        Args:\n",
    "            fitness_fn: Function to evaluate fitness\n",
    "            bounds: List of (min, max) for each dimension\n",
    "            population_size: Number of individuals\n",
    "            mutation_rate: Probability of mutation\n",
    "            crossover_rate: Probability of crossover\n",
    "            maximize: If True, maximize; else minimize\n",
    "        \"\"\"\n",
    "        self.fitness_fn = fitness_fn\n",
    "        self.bounds = bounds\n",
    "        self.n_dims = len(bounds)\n",
    "        self.population_size = population_size\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.maximize = maximize\n",
    "        \n",
    "        self.population = []\n",
    "        self.best_history = []\n",
    "        self.mean_history = []\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Create random initial population within bounds.\"\"\"\n",
    "        self.population = []\n",
    "        for _ in range(self.population_size):\n",
    "            individual = np.array([\n",
    "                np.random.uniform(low, high)\n",
    "                for low, high in self.bounds\n",
    "            ])\n",
    "            self.population.append(individual)\n",
    "    \n",
    "    def evaluate_population(self) -> List[float]:\n",
    "        \"\"\"Evaluate fitness of all individuals.\"\"\"\n",
    "        return [self.fitness_fn(ind) for ind in self.population]\n",
    "    \n",
    "    def tournament_selection(self, fitness_values: List[float]) -> np.ndarray:\n",
    "        \"\"\"Tournament selection.\"\"\"\n",
    "        tournament_size = 3\n",
    "        tournament_indices = random.sample(range(len(self.population)), \n",
    "                                          tournament_size)\n",
    "        tournament_fitness = [fitness_values[i] for i in tournament_indices]\n",
    "        \n",
    "        if self.maximize:\n",
    "            winner_idx = tournament_indices[np.argmax(tournament_fitness)]\n",
    "        else:\n",
    "            winner_idx = tournament_indices[np.argmin(tournament_fitness)]\n",
    "        \n",
    "        return self.population[winner_idx].copy()\n",
    "    \n",
    "    def blend_crossover(self, parent1: np.ndarray, \n",
    "                       parent2: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n",
    "        \"\"\"Blend crossover (BLX-Î±).\"\"\"\n",
    "        if random.random() > self.crossover_rate:\n",
    "            return parent1.copy()\n",
    "        \n",
    "        offspring = np.zeros(self.n_dims)\n",
    "        for i in range(self.n_dims):\n",
    "            min_val = min(parent1[i], parent2[i])\n",
    "            max_val = max(parent1[i], parent2[i])\n",
    "            range_val = max_val - min_val\n",
    "            \n",
    "            # Sample from [min - Î±*range, max + Î±*range]\n",
    "            offspring[i] = np.random.uniform(\n",
    "                min_val - alpha * range_val,\n",
    "                max_val + alpha * range_val\n",
    "            )\n",
    "            \n",
    "            # Clip to bounds\n",
    "            offspring[i] = np.clip(offspring[i], \n",
    "                                  self.bounds[i][0], \n",
    "                                  self.bounds[i][1])\n",
    "        \n",
    "        return offspring\n",
    "    \n",
    "    def gaussian_mutation(self, individual: np.ndarray, \n",
    "                         sigma: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"Gaussian mutation.\"\"\"\n",
    "        mutated = individual.copy()\n",
    "        for i in range(self.n_dims):\n",
    "            if random.random() < self.mutation_rate:\n",
    "                # Add gaussian noise\n",
    "                range_val = self.bounds[i][1] - self.bounds[i][0]\n",
    "                mutated[i] += np.random.normal(0, sigma * range_val)\n",
    "                \n",
    "                # Clip to bounds\n",
    "                mutated[i] = np.clip(mutated[i], \n",
    "                                    self.bounds[i][0], \n",
    "                                    self.bounds[i][1])\n",
    "        return mutated\n",
    "    \n",
    "    def evolve(self, generations: int = 100) -> Tuple[np.ndarray, float]:\n",
    "        \"\"\"Run genetic algorithm.\"\"\"\n",
    "        self.initialize_population()\n",
    "        self.best_history = []\n",
    "        self.mean_history = []\n",
    "        \n",
    "        for generation in range(generations):\n",
    "            # Evaluate\n",
    "            fitness_values = self.evaluate_population()\n",
    "            \n",
    "            # Track statistics\n",
    "            if self.maximize:\n",
    "                best_fitness = max(fitness_values)\n",
    "                best_idx = np.argmax(fitness_values)\n",
    "            else:\n",
    "                best_fitness = min(fitness_values)\n",
    "                best_idx = np.argmin(fitness_values)\n",
    "            \n",
    "            self.best_history.append(best_fitness)\n",
    "            self.mean_history.append(np.mean(fitness_values))\n",
    "            \n",
    "            # Create new population\n",
    "            new_population = []\n",
    "            \n",
    "            # Elitism\n",
    "            new_population.append(self.population[best_idx].copy())\n",
    "            \n",
    "            # Generate offspring\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1 = self.tournament_selection(fitness_values)\n",
    "                parent2 = self.tournament_selection(fitness_values)\n",
    "                \n",
    "                offspring = self.blend_crossover(parent1, parent2)\n",
    "                offspring = self.gaussian_mutation(offspring)\n",
    "                \n",
    "                new_population.append(offspring)\n",
    "            \n",
    "            self.population = new_population[:self.population_size]\n",
    "        \n",
    "        # Return best\n",
    "        final_fitness = self.evaluate_population()\n",
    "        if self.maximize:\n",
    "            best_idx = np.argmax(final_fitness)\n",
    "        else:\n",
    "            best_idx = np.argmin(final_fitness)\n",
    "        \n",
    "        return self.population[best_idx], final_fitness[best_idx]\n",
    "\n",
    "\n",
    "# Test on benchmark functions\n",
    "def sphere(x):\n",
    "    \"\"\"Sphere function: simple convex.\"\"\"\n",
    "    return np.sum(x**2)\n",
    "\n",
    "def rastrigin(x):\n",
    "    \"\"\"Rastrigin: highly multimodal.\"\"\"\n",
    "    A = 10\n",
    "    return A * len(x) + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n",
    "\n",
    "print(\"\\nReal-Valued GA on Benchmark Functions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test functions\n",
    "test_functions = [\n",
    "    (\"Sphere\", sphere, 2),\n",
    "    (\"Rastrigin\", rastrigin, 2)\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for ax, (name, func, dims) in zip(axes, test_functions):\n",
    "    bounds = [(-5, 5)] * dims\n",
    "    \n",
    "    ga = RealValuedGA(\n",
    "        fitness_fn=func,\n",
    "        bounds=bounds,\n",
    "        population_size=50,\n",
    "        mutation_rate=0.1,\n",
    "        crossover_rate=0.8,\n",
    "        maximize=False\n",
    "    )\n",
    "    \n",
    "    best_sol, best_fit = ga.evolve(generations=200)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Best solution: {best_sol}\")\n",
    "    print(f\"  Best fitness: {best_fit:.6f}\")\n",
    "    print()\n",
    "    \n",
    "    # Plot convergence\n",
    "    ax.plot(ga.best_history, label='Best', linewidth=2)\n",
    "    ax.plot(ga.mean_history, label='Mean', linewidth=2, alpha=0.7)\n",
    "    ax.set_xlabel('Generation', fontweight='bold')\n",
    "    ax.set_ylabel('Fitness', fontweight='bold')\n",
    "    ax.set_title(f'{name} Function', fontweight='bold')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: TSP with Genetic Algorithm\n",
    "\n",
    "For permutation problems like TSP, we need specialized operators:\n",
    "\n",
    "**Crossover**:\n",
    "- Order Crossover (OX)\n",
    "- Partially Mapped Crossover (PMX)\n",
    "\n",
    "**Mutation**:\n",
    "- Swap mutation\n",
    "- Inversion mutation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSP_GA:\n",
    "    \"\"\"Genetic Algorithm for Traveling Salesman Problem.\"\"\"\n",
    "    \n",
    "    def __init__(self, cities: np.ndarray, population_size: int = 100):\n",
    "        \"\"\"\n",
    "        Initialize TSP GA.\n",
    "        \n",
    "        Args:\n",
    "            cities: Array of city coordinates (n_cities, 2)\n",
    "            population_size: Number of tours in population\n",
    "        \"\"\"\n",
    "        self.cities = cities\n",
    "        self.n_cities = len(cities)\n",
    "        self.population_size = population_size\n",
    "        \n",
    "        # Precompute distances\n",
    "        self.distances = np.zeros((self.n_cities, self.n_cities))\n",
    "        for i in range(self.n_cities):\n",
    "            for j in range(self.n_cities):\n",
    "                self.distances[i, j] = np.linalg.norm(cities[i] - cities[j])\n",
    "        \n",
    "        self.population = []\n",
    "        self.best_history = []\n",
    "    \n",
    "    def tour_length(self, tour: List[int]) -> float:\n",
    "        \"\"\"Calculate total tour length.\"\"\"\n",
    "        length = 0\n",
    "        for i in range(len(tour)):\n",
    "            length += self.distances[tour[i], tour[(i + 1) % len(tour)]]\n",
    "        return length\n",
    "    \n",
    "    def initialize_population(self):\n",
    "        \"\"\"Create random initial population.\"\"\"\n",
    "        self.population = []\n",
    "        for _ in range(self.population_size):\n",
    "            tour = list(range(self.n_cities))\n",
    "            random.shuffle(tour)\n",
    "            self.population.append(tour)\n",
    "    \n",
    "    def tournament_selection(self, fitness_values: List[float]) -> List[int]:\n",
    "        \"\"\"Tournament selection.\"\"\"\n",
    "        tournament_size = 5\n",
    "        tournament_indices = random.sample(range(len(self.population)), \n",
    "                                          tournament_size)\n",
    "        tournament_fitness = [fitness_values[i] for i in tournament_indices]\n",
    "        winner_idx = tournament_indices[np.argmin(tournament_fitness)]  # Minimize distance\n",
    "        return self.population[winner_idx][:]\n",
    "    \n",
    "    def order_crossover(self, parent1: List[int], \n",
    "                       parent2: List[int]) -> List[int]:\n",
    "        \"\"\"Order Crossover (OX).\"\"\"\n",
    "        size = len(parent1)\n",
    "        \n",
    "        # Choose two random crossover points\n",
    "        start, end = sorted(random.sample(range(size), 2))\n",
    "        \n",
    "        # Copy segment from parent1\n",
    "        offspring = [-1] * size\n",
    "        offspring[start:end] = parent1[start:end]\n",
    "        \n",
    "        # Fill remaining from parent2\n",
    "        current_pos = end\n",
    "        for city in parent2[end:] + parent2[:end]:\n",
    "            if city not in offspring:\n",
    "                offspring[current_pos % size] = city\n",
    "                current_pos += 1\n",
    "        \n",
    "        return offspring\n",
    "    \n",
    "    def swap_mutation(self, tour: List[int], rate: float = 0.1) -> List[int]:\n",
    "        \"\"\"Swap mutation.\"\"\"\n",
    "        mutated = tour[:]\n",
    "        if random.random() < rate:\n",
    "            i, j = random.sample(range(len(tour)), 2)\n",
    "            mutated[i], mutated[j] = mutated[j], mutated[i]\n",
    "        return mutated\n",
    "    \n",
    "    def evolve(self, generations: int = 500) -> Tuple[List[int], float]:\n",
    "        \"\"\"Run genetic algorithm.\"\"\"\n",
    "        self.initialize_population()\n",
    "        self.best_history = []\n",
    "        \n",
    "        for generation in range(generations):\n",
    "            # Evaluate\n",
    "            fitness_values = [self.tour_length(tour) for tour in self.population]\n",
    "            \n",
    "            # Track best\n",
    "            best_idx = np.argmin(fitness_values)\n",
    "            best_fitness = fitness_values[best_idx]\n",
    "            self.best_history.append(best_fitness)\n",
    "            \n",
    "            # Create new population\n",
    "            new_population = []\n",
    "            \n",
    "            # Elitism\n",
    "            new_population.append(self.population[best_idx][:])\n",
    "            \n",
    "            # Generate offspring\n",
    "            while len(new_population) < self.population_size:\n",
    "                parent1 = self.tournament_selection(fitness_values)\n",
    "                parent2 = self.tournament_selection(fitness_values)\n",
    "                \n",
    "                offspring = self.order_crossover(parent1, parent2)\n",
    "                offspring = self.swap_mutation(offspring, rate=0.2)\n",
    "                \n",
    "                new_population.append(offspring)\n",
    "            \n",
    "            self.population = new_population[:self.population_size]\n",
    "        \n",
    "        # Return best\n",
    "        final_fitness = [self.tour_length(tour) for tour in self.population]\n",
    "        best_idx = np.argmin(final_fitness)\n",
    "        return self.population[best_idx], final_fitness[best_idx]\n",
    "\n",
    "\n",
    "# Test on TSP\n",
    "print(\"Genetic Algorithm for TSP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate random cities\n",
    "np.random.seed(42)\n",
    "n_cities = 20\n",
    "cities = np.random.rand(n_cities, 2) * 100\n",
    "\n",
    "tsp_ga = TSP_GA(cities, population_size=100)\n",
    "\n",
    "print(f\"Solving TSP with {n_cities} cities...\")\n",
    "best_tour, best_length = tsp_ga.evolve(generations=500)\n",
    "\n",
    "print(f\"Best tour length: {best_length:.2f}\")\n",
    "print()\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot tour\n",
    "tour_coords = np.array([cities[i] for i in best_tour + [best_tour[0]]])\n",
    "ax1.plot(tour_coords[:, 0], tour_coords[:, 1], 'b-', linewidth=2, alpha=0.6)\n",
    "ax1.scatter(cities[:, 0], cities[:, 1], s=200, c='red', \n",
    "           zorder=5, edgecolors='black', linewidths=2)\n",
    "ax1.set_xlabel('X', fontweight='bold')\n",
    "ax1.set_ylabel('Y', fontweight='bold')\n",
    "ax1.set_title(f'Best Tour (Length: {best_length:.2f})', \n",
    "             fontweight='bold', fontsize=13)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.axis('equal')\n",
    "\n",
    "# Plot convergence\n",
    "ax2.plot(tsp_ga.best_history, linewidth=2, color='blue')\n",
    "ax2.set_xlabel('Generation', fontweight='bold')\n",
    "ax2.set_ylabel('Best Tour Length', fontweight='bold')\n",
    "ax2.set_title('GA Convergence on TSP', fontweight='bold', fontsize=13)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Feature Selection with GA\n",
    "\n",
    "### Application: Feature Selection for ML\n",
    "\n",
    "**Problem**: Select subset of features that maximizes model performance.\n",
    "\n",
    "**Encoding**: Binary chromosome where 1 = include feature, 0 = exclude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection example (synthetic data)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "print(\"Feature Selection with Genetic Algorithm\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Generate synthetic classification dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "print()\n",
    "\n",
    "def feature_selection_fitness(chromosome: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Fitness = cross-validation accuracy with selected features.\n",
    "    Penalty for too many features.\n",
    "    \"\"\"\n",
    "    # Select features\n",
    "    selected_features = np.where(chromosome == 1)[0]\n",
    "    \n",
    "    if len(selected_features) == 0:\n",
    "        return 0.0  # No features selected\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    X_selected = X[:, selected_features]\n",
    "    clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    scores = cross_val_score(clf, X_selected, y, cv=3, scoring='accuracy')\n",
    "    accuracy = scores.mean()\n",
    "    \n",
    "    # Penalty for using too many features (encourage parsimony)\n",
    "    n_features_penalty = len(selected_features) / len(chromosome) * 0.1\n",
    "    \n",
    "    return accuracy - n_features_penalty\n",
    "\n",
    "# Run GA for feature selection\n",
    "ga_fs = GeneticAlgorithm(\n",
    "    fitness_fn=feature_selection_fitness,\n",
    "    chromosome_length=X.shape[1],\n",
    "    population_size=50,\n",
    "    mutation_rate=0.05,\n",
    "    crossover_rate=0.8,\n",
    "    maximize=True\n",
    ")\n",
    "\n",
    "best_features, best_fitness = ga_fs.evolve(generations=50)\n",
    "\n",
    "selected = np.where(best_features == 1)[0]\n",
    "print(f\"Best fitness: {best_fitness:.4f}\")\n",
    "print(f\"Selected {len(selected)} features: {selected.tolist()}\")\n",
    "print()\n",
    "\n",
    "# Compare with using all features\n",
    "clf_all = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "scores_all = cross_val_score(clf_all, X, y, cv=3, scoring='accuracy')\n",
    "accuracy_all = scores_all.mean()\n",
    "\n",
    "clf_selected = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "scores_selected = cross_val_score(clf_selected, X[:, selected], y, cv=3, scoring='accuracy')\n",
    "accuracy_selected = scores_selected.mean()\n",
    "\n",
    "print(\"Comparison:\")\n",
    "print(f\"  All features ({X.shape[1]}): {accuracy_all:.4f}\")\n",
    "print(f\"  Selected features ({len(selected)}): {accuracy_selected:.4f}\")\n",
    "print()\n",
    "print(\"GA found a compact feature set with similar performance!\")\n",
    "\n",
    "# Plot convergence\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ga_fs.fitness_history, linewidth=2, color='green')\n",
    "plt.axhline(y=accuracy_all, color='r', linestyle='--', \n",
    "           label=f'All features: {accuracy_all:.3f}', linewidth=2)\n",
    "plt.xlabel('Generation', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('Fitness', fontweight='bold', fontsize=12)\n",
    "plt.title('Feature Selection with GA', fontweight='bold', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Parameter Tuning\n",
    "\n",
    "### Impact of GA Parameters\n",
    "\n",
    "Key parameters to tune:\n",
    "- **Population size**: Larger = more diversity, slower\n",
    "- **Mutation rate**: Higher = more exploration\n",
    "- **Crossover rate**: Usually 0.6-0.9\n",
    "- **Selection pressure**: Tournament size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameter Sensitivity Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test function\n",
    "def rastrigin_2d(x):\n",
    "    A = 10\n",
    "    return A * 2 + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n",
    "\n",
    "# Test different mutation rates\n",
    "mutation_rates = [0.01, 0.05, 0.1, 0.2]\n",
    "results = []\n",
    "\n",
    "for mr in mutation_rates:\n",
    "    ga = RealValuedGA(\n",
    "        fitness_fn=rastrigin_2d,\n",
    "        bounds=[(-5, 5), (-5, 5)],\n",
    "        population_size=50,\n",
    "        mutation_rate=mr,\n",
    "        crossover_rate=0.8,\n",
    "        maximize=False\n",
    "    )\n",
    "    \n",
    "    best_sol, best_fit = ga.evolve(generations=100)\n",
    "    results.append((mr, ga.best_history))\n",
    "    print(f\"Mutation rate {mr:.2f}: Final fitness = {best_fit:.4f}\")\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "for mr, history in results:\n",
    "    plt.plot(history, label=f'Mutation rate = {mr}', linewidth=2)\n",
    "\n",
    "plt.xlabel('Generation', fontweight='bold', fontsize=12)\n",
    "plt.ylabel('Best Fitness', fontweight='bold', fontsize=12)\n",
    "plt.title('Impact of Mutation Rate on Convergence', fontweight='bold', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.yscale('log')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"- Low mutation: Fast initial convergence, may get stuck\")\n",
    "print(\"- High mutation: Slower but better exploration\")\n",
    "print(\"- Sweet spot typically around 0.05-0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Custom Fitness Function\n",
    "Create a custom optimization problem and solve it with GA.\n",
    "Compare results with different parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design and solve custom problem\n",
    "# Your code here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Knapsack with GA\n",
    "Solve the 0-1 knapsack problem from Lab 1 using genetic algorithm.\n",
    "Compare with greedy solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement knapsack with GA\n",
    "# Your code here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Multi-Objective Optimization\n",
    "Implement NSGA-II for multi-objective optimization.\n",
    "Solve a problem with two conflicting objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement multi-objective GA\n",
    "# Your code here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Evolution-inspired** - Population, selection, variation\n",
    "2. **Encoding matters** - Binary, real-valued, permutation\n",
    "3. **Operators** - Crossover and mutation for exploration\n",
    "4. **Selection pressure** - Balance exploitation vs exploration\n",
    "5. **Parameter tuning** - Critical for performance\n",
    "6. **Applications** - TSP, feature selection, design optimization\n",
    "\n",
    "### When to Use GAs\n",
    "\n",
    "**Good fit**:\n",
    "- Complex, non-differentiable objectives\n",
    "- Large search spaces\n",
    "- Multiple local optima\n",
    "- Discrete or mixed variables\n",
    "- Black-box optimization\n",
    "\n",
    "**Not ideal**:\n",
    "- Small problems (use exact methods)\n",
    "- Smooth, convex problems (use gradient methods)\n",
    "- Need guaranteed optimality\n",
    "- Very tight time constraints\n",
    "\n",
    "### GA Variants\n",
    "\n",
    "- **NSGA-II**: Multi-objective optimization\n",
    "- **CMA-ES**: Covariance matrix adaptation\n",
    "- **Differential Evolution**: Alternative operators\n",
    "- **Genetic Programming**: Evolve programs/trees\n",
    "- **Neuroevolution**: Evolve neural networks\n",
    "\n",
    "### Week 4 Complete!\n",
    "\n",
    "You've now mastered:\n",
    "1. **Optimization fundamentals** (Lab 1)\n",
    "2. **Local search** (Lab 2)\n",
    "3. **Constraint satisfaction** (Lab 3)\n",
    "4. **Evolutionary algorithms** (Lab 4)\n",
    "\n",
    "Ready for **Week 5: Machine Learning**! ðŸš€\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
