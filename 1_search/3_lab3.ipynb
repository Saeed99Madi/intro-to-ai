{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1, Lab 3: Adversarial Search (Game-Playing AI)\n",
    "\n",
    "## Welcome to Game AI!\n",
    "\n",
    "So far, we've been solving problems where we control all the actions. But what about games where we face an **opponent** trying to beat us?\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "- Game trees and game states\n",
    "- Minimax algorithm\n",
    "- Alpha-Beta pruning optimization\n",
    "- Evaluation functions\n",
    "- Building a Tic-Tac-Toe AI\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "- Chess engines (Deep Blue, Stockfish)\n",
    "- Go AI (AlphaGo)\n",
    "- Video game opponents\n",
    "- Poker bots\n",
    "- Strategy game AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Optional\n",
    "from copy import deepcopy\n",
    "import time\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Game Theory Basics\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Two players**: Usually called MAX and MIN\n",
    "   - MAX wants to maximize the score\n",
    "   - MIN wants to minimize the score\n",
    "\n",
    "2. **Zero-sum game**: One player's gain is another's loss\n",
    "\n",
    "3. **Perfect information**: Both players can see everything\n",
    "\n",
    "4. **Game tree**: All possible moves form a tree structure\n",
    "\n",
    "### Simple Example: Number Picking Game\n",
    "\n",
    "- Two players take turns\n",
    "- Each picks a number from 1-3\n",
    "- First to reach exactly 10 wins\n",
    "- Going over 10 loses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_game_tree_simple():\n",
    "    \"\"\"\n",
    "    Visualize a simple 2-ply game tree.\n",
    "    \n",
    "    In game terminology:\n",
    "    - Ply = one player's turn\n",
    "    - Depth = number of plies\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Draw nodes at different levels\n",
    "    # Level 0: MAX's turn\n",
    "    ax.plot(5, 4, 'ro', markersize=20)\n",
    "    ax.text(5, 4, 'MAX', ha='center', va='center', fontweight='bold')\n",
    "    \n",
    "    # Level 1: MIN's responses\n",
    "    min_positions = [(2, 3), (5, 3), (8, 3)]\n",
    "    for x, y in min_positions:\n",
    "        ax.plot(x, y, 'bo', markersize=20)\n",
    "        ax.text(x, y, 'MIN', ha='center', va='center', fontweight='bold', color='white')\n",
    "        ax.plot([5, x], [4, y], 'k-', linewidth=2)\n",
    "    \n",
    "    # Level 2: MAX's responses (terminal states with values)\n",
    "    outcomes = [\n",
    "        [(0.5, 2, 3), (1.5, 2, 5), (2.5, 2, -2)],  # From first MIN\n",
    "        [(4, 2, 1), (5, 2, -1), (6, 2, 4)],         # From second MIN\n",
    "        [(7, 2, 2), (8, 2, 6), (9, 2, -3)]          # From third MIN\n",
    "    ]\n",
    "    \n",
    "    for parent_idx, outcomes_group in enumerate(outcomes):\n",
    "        parent_x, parent_y = min_positions[parent_idx]\n",
    "        for x, y, value in outcomes_group:\n",
    "            # Color based on value\n",
    "            color = 'green' if value > 0 else 'red' if value < 0 else 'gray'\n",
    "            ax.plot(x, y, 'o', color=color, markersize=15)\n",
    "            ax.text(x, y, str(value), ha='center', va='center', fontweight='bold')\n",
    "            ax.plot([parent_x, x], [parent_y, y], 'k-', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Labels\n",
    "    ax.text(-0.5, 4, 'Depth 0\\n(MAX)', fontsize=10, ha='right')\n",
    "    ax.text(-0.5, 3, 'Depth 1\\n(MIN)', fontsize=10, ha='right')\n",
    "    ax.text(-0.5, 2, 'Depth 2\\n(Terminal)', fontsize=10, ha='right')\n",
    "    \n",
    "    ax.set_xlim(-1, 10)\n",
    "    ax.set_ylim(1.5, 4.5)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Simple Game Tree\\nMAX maximizes, MIN minimizes', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_game_tree_simple()\n",
    "\n",
    "print(\"Game Tree Explanation:\")\n",
    "print(\"- Red nodes: MAX's turn (wants high scores)\")\n",
    "print(\"- Blue nodes: MIN's turn (wants low scores)\")\n",
    "print(\"- Leaf nodes show final game values\")\n",
    "print(\"- Green = good for MAX, Red = good for MIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building Tic-Tac-Toe\n",
    "\n",
    "Let's implement a complete Tic-Tac-Toe game as our testbed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    \"\"\"Tic-Tac-Toe game implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Board: 0 = empty, 1 = X, -1 = O\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1  # X starts\n",
    "    \n",
    "    def get_valid_moves(self) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Return list of valid (row, col) moves.\"\"\"\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "    \n",
    "    def make_move(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Make a move. Returns True if valid.\"\"\"\n",
    "        if self.board[row, col] == 0:\n",
    "            self.board[row, col] = self.current_player\n",
    "            self.current_player *= -1  # Switch player\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def check_winner(self) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Check if there's a winner.\n",
    "        Returns: 1 (X wins), -1 (O wins), 0 (draw), None (game continues)\n",
    "        \"\"\"\n",
    "        # Check rows\n",
    "        for i in range(3):\n",
    "            if abs(self.board[i, :].sum()) == 3:\n",
    "                return self.board[i, 0]\n",
    "        \n",
    "        # Check columns\n",
    "        for j in range(3):\n",
    "            if abs(self.board[:, j].sum()) == 3:\n",
    "                return self.board[0, j]\n",
    "        \n",
    "        # Check diagonals\n",
    "        if abs(self.board.trace()) == 3:\n",
    "            return self.board[0, 0]\n",
    "        if abs(np.fliplr(self.board).trace()) == 3:\n",
    "            return self.board[0, 2]\n",
    "        \n",
    "        # Check for draw\n",
    "        if len(self.get_valid_moves()) == 0:\n",
    "            return 0\n",
    "        \n",
    "        return None  # Game continues\n",
    "    \n",
    "    def is_terminal(self) -> bool:\n",
    "        \"\"\"Check if game is over.\"\"\"\n",
    "        return self.check_winner() is not None\n",
    "    \n",
    "    def copy(self):\n",
    "        \"\"\"Create a deep copy of the game state.\"\"\"\n",
    "        new_game = TicTacToe()\n",
    "        new_game.board = self.board.copy()\n",
    "        new_game.current_player = self.current_player\n",
    "        return new_game\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Visualize the board.\"\"\"\n",
    "        symbols = {0: ' ', 1: 'X', -1: 'O'}\n",
    "        print(\"\\n  0   1   2\")\n",
    "        for i in range(3):\n",
    "            row_str = f\"{i} \"\n",
    "            for j in range(3):\n",
    "                row_str += f\" {symbols[self.board[i, j]]} \"\n",
    "                if j < 2:\n",
    "                    row_str += \"│\"\n",
    "            print(row_str)\n",
    "            if i < 2:\n",
    "                print(\"  ───┼───┼───\")\n",
    "        print()\n",
    "\n",
    "# Test the game\n",
    "game = TicTacToe()\n",
    "game.display()\n",
    "game.make_move(1, 1)  # X in center\n",
    "game.make_move(0, 0)  # O in corner\n",
    "game.make_move(0, 2)  # X in corner\n",
    "game.display()\n",
    "print(f\"Valid moves: {game.get_valid_moves()}\")\n",
    "print(f\"Winner: {game.check_winner()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimax Algorithm\n",
    "\n",
    "Minimax is the foundation of game AI. It assumes both players play **optimally**.\n",
    "\n",
    "### How Minimax Works:\n",
    "\n",
    "1. **Build the game tree** of all possible moves\n",
    "2. **At terminal nodes**, assign values (win/loss/draw)\n",
    "3. **Propagate values up** the tree:\n",
    "   - MAX nodes: Choose the **maximum** child value\n",
    "   - MIN nodes: Choose the **minimum** child value\n",
    "4. **Root node value** is the best outcome for MAX with optimal play\n",
    "\n",
    "### Pseudocode:\n",
    "\n",
    "```python\n",
    "def minimax(state, is_maximizing):\n",
    "    if state.is_terminal():\n",
    "        return evaluate(state)\n",
    "    \n",
    "    if is_maximizing:\n",
    "        best = -infinity\n",
    "        for each move:\n",
    "            value = minimax(resulting_state, False)\n",
    "            best = max(best, value)\n",
    "        return best\n",
    "    else:\n",
    "        best = +infinity\n",
    "        for each move:\n",
    "            value = minimax(resulting_state, True)\n",
    "            best = min(best, value)\n",
    "        return best\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(game: TicTacToe, is_maximizing: bool, depth: int = 0) -> Tuple[int, Optional[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Minimax algorithm for Tic-Tac-Toe.\n",
    "    \n",
    "    Args:\n",
    "        game: Current game state\n",
    "        is_maximizing: True if MAX's turn (X), False if MIN's turn (O)\n",
    "        depth: Current depth in tree (for tie-breaking)\n",
    "    \n",
    "    Returns:\n",
    "        (best_value, best_move)\n",
    "    \"\"\"\n",
    "    # Terminal state: return the value\n",
    "    winner = game.check_winner()\n",
    "    if winner is not None:\n",
    "        if winner == 1:  # X (MAX) wins\n",
    "            return (10 - depth, None)  # Prefer faster wins\n",
    "        elif winner == -1:  # O (MIN) wins\n",
    "            return (-10 + depth, None)  # Prefer slower losses\n",
    "        else:  # Draw\n",
    "            return (0, None)\n",
    "    \n",
    "    valid_moves = game.get_valid_moves()\n",
    "    \n",
    "    if is_maximizing:  # MAX's turn (X)\n",
    "        best_value = -float('inf')\n",
    "        best_move = None\n",
    "        \n",
    "        for move in valid_moves:\n",
    "            # Try this move\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            \n",
    "            # Recursively get the value\n",
    "            value, _ = minimax(new_game, False, depth + 1)\n",
    "            \n",
    "            # Update best\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "        \n",
    "        return (best_value, best_move)\n",
    "    \n",
    "    else:  # MIN's turn (O)\n",
    "        best_value = float('inf')\n",
    "        best_move = None\n",
    "        \n",
    "        for move in valid_moves:\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            \n",
    "            value, _ = minimax(new_game, True, depth + 1)\n",
    "            \n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "        \n",
    "        return (best_value, best_move)\n",
    "\n",
    "# Test minimax on an empty board\n",
    "game = TicTacToe()\n",
    "print(\"Finding best move for X (MAX) on empty board...\")\n",
    "start_time = time.time()\n",
    "value, move = minimax(game, is_maximizing=True)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"Best move: {move}\")\n",
    "print(f\"Expected value: {value}\")\n",
    "print(f\"Time taken: {elapsed:.3f} seconds\")\n",
    "print(f\"\\nWith perfect play, the game should end in a {'X win' if value > 0 else 'O win' if value < 0 else 'draw'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Let's Play Against Minimax!\n",
    "\n",
    "Try to beat the AI (spoiler: you can't if it's perfect!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game_vs_ai(human_first: bool = True, use_alpha_beta: bool = False):\n",
    "    \"\"\"\n",
    "    Play Tic-Tac-Toe against the AI.\n",
    "    \n",
    "    Args:\n",
    "        human_first: If True, human plays X (goes first)\n",
    "        use_alpha_beta: If True, use alpha-beta pruning (we'll implement this next!)\n",
    "    \"\"\"\n",
    "    game = TicTacToe()\n",
    "    human_player = 1 if human_first else -1\n",
    "    ai_player = -human_player\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TIC-TAC-TOE vs AI\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"You are {'X (first)' if human_first else 'O (second)'}\")\n",
    "    print(\"Enter moves as 'row col' (e.g., '1 1' for center)\\n\")\n",
    "    \n",
    "    moves_count = 0\n",
    "    \n",
    "    while not game.is_terminal():\n",
    "        game.display()\n",
    "        \n",
    "        if game.current_player == human_player:\n",
    "            # Human's turn\n",
    "            valid = False\n",
    "            while not valid:\n",
    "                try:\n",
    "                    move_input = input(\"Your move (row col): \").strip().split()\n",
    "                    row, col = int(move_input[0]), int(move_input[1])\n",
    "                    valid = game.make_move(row, col)\n",
    "                    if not valid:\n",
    "                        print(\"Invalid move! Try again.\")\n",
    "                except (ValueError, IndexError):\n",
    "                    print(\"Invalid input! Use format 'row col' (0-2)\")\n",
    "        else:\n",
    "            # AI's turn\n",
    "            print(\"AI is thinking...\")\n",
    "            start = time.time()\n",
    "            \n",
    "            is_maximizing = (ai_player == 1)\n",
    "            _, move = minimax(game, is_maximizing)\n",
    "            \n",
    "            elapsed = time.time() - start\n",
    "            print(f\"AI chose {move} (took {elapsed:.3f}s)\")\n",
    "            game.make_move(move[0], move[1])\n",
    "        \n",
    "        moves_count += 1\n",
    "    \n",
    "    # Game over\n",
    "    game.display()\n",
    "    winner = game.check_winner()\n",
    "    \n",
    "    if winner == human_player:\n",
    "        print(\"🎉 You won! (Wait, that shouldn't be possible with perfect AI...)\")\n",
    "    elif winner == ai_player:\n",
    "        print(\"🤖 AI wins! Better luck next time.\")\n",
    "    else:\n",
    "        print(\"🤝 It's a draw! Well played.\")\n",
    "    \n",
    "    print(f\"\\nGame finished in {moves_count} moves.\")\n",
    "\n",
    "# Uncomment to play (interactive)\n",
    "# play_game_vs_ai(human_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Alpha-Beta Pruning ✂️\n",
    "\n",
    "Minimax explores **every** possible move. But we can skip many branches that won't affect the final decision!\n",
    "\n",
    "### The Key Insight:\n",
    "\n",
    "- **Alpha (α)**: Best value MAX can guarantee so far\n",
    "- **Beta (β)**: Best value MIN can guarantee so far\n",
    "\n",
    "If we find a move that's worse than what we can already guarantee, we can **prune** (skip) it!\n",
    "\n",
    "### Example:\n",
    "```\n",
    "MAX is choosing between branches:\n",
    "- Branch A evaluated to 5\n",
    "- Branch B: First child is 3, and it's MIN's turn\n",
    "  → MIN will choose ≤ 3\n",
    "  → No need to check other children of Branch B!\n",
    "  → Branch A (5) is better than Branch B (≤3)\n",
    "```\n",
    "\n",
    "### Performance:\n",
    "- Minimax: Explores O(b^d) nodes\n",
    "- Alpha-Beta: Explores O(b^(d/2)) nodes with good move ordering\n",
    "- **Same result, much faster!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global counters for comparison\n",
    "minimax_nodes = 0\n",
    "alphabeta_nodes = 0\n",
    "\n",
    "def minimax_with_count(game: TicTacToe, is_maximizing: bool, depth: int = 0) -> Tuple[int, Optional[Tuple[int, int]]]:\n",
    "    \"\"\"Minimax with node counting.\"\"\"\n",
    "    global minimax_nodes\n",
    "    minimax_nodes += 1\n",
    "    \n",
    "    winner = game.check_winner()\n",
    "    if winner is not None:\n",
    "        if winner == 1:\n",
    "            return (10 - depth, None)\n",
    "        elif winner == -1:\n",
    "            return (-10 + depth, None)\n",
    "        else:\n",
    "            return (0, None)\n",
    "    \n",
    "    valid_moves = game.get_valid_moves()\n",
    "    best_move = None\n",
    "    \n",
    "    if is_maximizing:\n",
    "        best_value = -float('inf')\n",
    "        for move in valid_moves:\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            value, _ = minimax_with_count(new_game, False, depth + 1)\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "        return (best_value, best_move)\n",
    "    else:\n",
    "        best_value = float('inf')\n",
    "        for move in valid_moves:\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            value, _ = minimax_with_count(new_game, True, depth + 1)\n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "        return (best_value, best_move)\n",
    "\n",
    "\n",
    "def alpha_beta(game: TicTacToe, is_maximizing: bool, \n",
    "               alpha: float = -float('inf'), beta: float = float('inf'), \n",
    "               depth: int = 0) -> Tuple[int, Optional[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Alpha-Beta Pruning - optimized minimax.\n",
    "    \n",
    "    Args:\n",
    "        game: Current game state\n",
    "        is_maximizing: True if MAX's turn\n",
    "        alpha: Best value for MAX so far\n",
    "        beta: Best value for MIN so far\n",
    "        depth: Current depth\n",
    "    \n",
    "    Returns:\n",
    "        (best_value, best_move)\n",
    "    \"\"\"\n",
    "    global alphabeta_nodes\n",
    "    alphabeta_nodes += 1\n",
    "    \n",
    "    # Terminal state\n",
    "    winner = game.check_winner()\n",
    "    if winner is not None:\n",
    "        if winner == 1:\n",
    "            return (10 - depth, None)\n",
    "        elif winner == -1:\n",
    "            return (-10 + depth, None)\n",
    "        else:\n",
    "            return (0, None)\n",
    "    \n",
    "    valid_moves = game.get_valid_moves()\n",
    "    best_move = None\n",
    "    \n",
    "    if is_maximizing:  # MAX's turn\n",
    "        best_value = -float('inf')\n",
    "        \n",
    "        for move in valid_moves:\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            \n",
    "            value, _ = alpha_beta(new_game, False, alpha, beta, depth + 1)\n",
    "            \n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "            \n",
    "            alpha = max(alpha, best_value)\n",
    "            \n",
    "            # Beta cutoff: MIN won't let us get here\n",
    "            if beta <= alpha:\n",
    "                break  # Prune remaining branches\n",
    "        \n",
    "        return (best_value, best_move)\n",
    "    \n",
    "    else:  # MIN's turn\n",
    "        best_value = float('inf')\n",
    "        \n",
    "        for move in valid_moves:\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            \n",
    "            value, _ = alpha_beta(new_game, True, alpha, beta, depth + 1)\n",
    "            \n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "            \n",
    "            beta = min(beta, best_value)\n",
    "            \n",
    "            # Alpha cutoff: MAX won't let us get here\n",
    "            if beta <= alpha:\n",
    "                break  # Prune remaining branches\n",
    "        \n",
    "        return (best_value, best_move)\n",
    "\n",
    "# Compare performance\n",
    "game = TicTacToe()\n",
    "print(\"Performance Comparison: Minimax vs Alpha-Beta Pruning\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test minimax\n",
    "minimax_nodes = 0\n",
    "start = time.time()\n",
    "value1, move1 = minimax_with_count(game, True)\n",
    "time1 = time.time() - start\n",
    "\n",
    "# Test alpha-beta\n",
    "alphabeta_nodes = 0\n",
    "start = time.time()\n",
    "value2, move2 = alpha_beta(game, True)\n",
    "time2 = time.time() - start\n",
    "\n",
    "print(f\"\\nMinimax:\")\n",
    "print(f\"  Nodes explored: {minimax_nodes:,}\")\n",
    "print(f\"  Time: {time1:.4f}s\")\n",
    "print(f\"  Best move: {move1}, Value: {value1}\")\n",
    "\n",
    "print(f\"\\nAlpha-Beta:\")\n",
    "print(f\"  Nodes explored: {alphabeta_nodes:,}\")\n",
    "print(f\"  Time: {time2:.4f}s\")\n",
    "print(f\"  Best move: {move2}, Value: {value2}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Improvement:\")\n",
    "print(f\"  Nodes pruned: {minimax_nodes - alphabeta_nodes:,} ({(1 - alphabeta_nodes/minimax_nodes)*100:.1f}% reduction)\")\n",
    "print(f\"  Speedup: {time1/time2:.2f}x faster\")\n",
    "print(f\"  Same result? {value1 == value2 and move1 == move2} ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing Pruning\n",
    "\n",
    "Let's see alpha-beta pruning in action with a simplified game tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_alpha_beta_pruning():\n",
    "    \"\"\"\n",
    "    Visualize which branches get pruned.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Left: Full minimax tree\n",
    "    ax1.set_title('Minimax (explores everything)', fontsize=14, fontweight='bold')\n",
    "    ax1.text(5, 4, 'MAX\\n?', ha='center', va='center', bbox=dict(boxstyle='round', facecolor='red', alpha=0.5))\n",
    "    \n",
    "    # MIN layer\n",
    "    for x in [2, 5, 8]:\n",
    "        ax1.plot([5, x], [4, 3], 'k-', linewidth=2)\n",
    "        ax1.text(x, 3, 'MIN\\n?', ha='center', va='center', bbox=dict(boxstyle='round', facecolor='blue', alpha=0.5))\n",
    "    \n",
    "    # Terminal nodes\n",
    "    terminals = [\n",
    "        [1, 1.5, '3'], [2, 1.5, '5'], [3, 1.5, '2'],  # First MIN\n",
    "        [4, 1.5, '1'], [5, 1.5, '4'], [6, 1.5, '6'],  # Second MIN\n",
    "        [7, 1.5, '7'], [8, 1.5, '2'], [9, 1.5, '5'],  # Third MIN\n",
    "    ]\n",
    "    \n",
    "    parents = [2, 2, 2, 5, 5, 5, 8, 8, 8]\n",
    "    for i, (x, y, val) in enumerate(terminals):\n",
    "        ax1.plot([parents[i], x], [3, y], 'k-', linewidth=1, alpha=0.5)\n",
    "        ax1.text(x, y, val, ha='center', va='center', \n",
    "                bbox=dict(boxstyle='round', facecolor='white'))\n",
    "    \n",
    "    ax1.set_xlim(0, 10)\n",
    "    ax1.set_ylim(1, 4.5)\n",
    "    ax1.axis('off')\n",
    "    ax1.text(5, 0.5, f'Nodes explored: {len(terminals) + 4}', ha='center', fontsize=12)\n",
    "    \n",
    "    # Right: Alpha-beta pruned tree\n",
    "    ax2.set_title('Alpha-Beta (prunes branches)', fontsize=14, fontweight='bold')\n",
    "    ax2.text(5, 4, 'MAX\\n6', ha='center', va='center', bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "    \n",
    "    # MIN layer with values\n",
    "    min_values = [(2, '2'), (5, '1'), (8, '2')]\n",
    "    for x, val in min_values:\n",
    "        ax2.plot([5, x], [4, 3], 'k-', linewidth=2)\n",
    "        ax2.text(x, 3, f'MIN\\n{val}', ha='center', va='center', \n",
    "                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "    \n",
    "    # Show evaluated and pruned terminals\n",
    "    evaluated = [\n",
    "        (1, 1.5, '3', 2, False),\n",
    "        (2, 1.5, '5', 2, False),\n",
    "        (3, 1.5, '2', 2, False),\n",
    "        (4, 1.5, '1', 5, False),\n",
    "        (5, 1.5, '4', 5, True),  # PRUNED\n",
    "        (6, 1.5, '6', 5, True),  # PRUNED\n",
    "        (7, 1.5, '7', 8, True),  # PRUNED\n",
    "        (8, 1.5, '2', 8, True),  # PRUNED\n",
    "        (9, 1.5, '5', 8, True),  # PRUNED\n",
    "    ]\n",
    "    \n",
    "    for x, y, val, parent, pruned in evaluated:\n",
    "        color = 'lightgray' if pruned else 'white'\n",
    "        alpha_line = 0.2 if pruned else 1.0\n",
    "        ax2.plot([parent, x], [3, y], 'k-', linewidth=1, alpha=alpha_line)\n",
    "        \n",
    "        text = '✂️' if pruned else val\n",
    "        ax2.text(x, y, text, ha='center', va='center',\n",
    "                bbox=dict(boxstyle='round', facecolor=color))\n",
    "    \n",
    "    ax2.set_xlim(0, 10)\n",
    "    ax2.set_ylim(1, 4.5)\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    explored = sum(1 for _, _, _, _, p in evaluated if not p) + 4\n",
    "    ax2.text(5, 0.5, f'Nodes explored: {explored} (saved {len(terminals) + 4 - explored})', \n",
    "            ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_alpha_beta_pruning()\n",
    "\n",
    "print(\"\\nHow Alpha-Beta Works:\")\n",
    "print(\"1. MAX explores first MIN node, gets value 2\")\n",
    "print(\"2. MAX now knows it can get at least 2\")\n",
    "print(\"3. MAX explores second MIN node\")\n",
    "print(\"4. Second MIN's first child is 1 (< 2)\")\n",
    "print(\"5. MIN will choose ≤ 1, so MAX won't pick this branch\")\n",
    "print(\"6. ✂️ PRUNE remaining children of second MIN!\")\n",
    "print(\"7. Continue with third branch...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Move Ordering Matters!\n",
    "\n",
    "Alpha-beta prunes more when we check better moves first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_beta_with_ordering(game: TicTacToe, is_maximizing: bool,\n",
    "                            alpha: float = -float('inf'), \n",
    "                            beta: float = float('inf'),\n",
    "                            depth: int = 0) -> Tuple[int, Optional[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Alpha-Beta with simple move ordering heuristic.\n",
    "    Tries center and corners first (usually better in Tic-Tac-Toe).\n",
    "    \"\"\"\n",
    "    winner = game.check_winner()\n",
    "    if winner is not None:\n",
    "        if winner == 1:\n",
    "            return (10 - depth, None)\n",
    "        elif winner == -1:\n",
    "            return (-10 + depth, None)\n",
    "        else:\n",
    "            return (0, None)\n",
    "    \n",
    "    valid_moves = game.get_valid_moves()\n",
    "    \n",
    "    # Move ordering: prioritize center, then corners, then edges\n",
    "    def move_priority(move):\n",
    "        r, c = move\n",
    "        if (r, c) == (1, 1):  # Center\n",
    "            return 0\n",
    "        elif (r + c) % 2 == 0:  # Corners\n",
    "            return 1\n",
    "        else:  # Edges\n",
    "            return 2\n",
    "    \n",
    "    valid_moves.sort(key=move_priority)\n",
    "    \n",
    "    best_move = None\n",
    "    \n",
    "    if is_maximizing:\n",
    "        best_value = -float('inf')\n",
    "        for move in valid_moves:\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            value, _ = alpha_beta_with_ordering(new_game, False, alpha, beta, depth + 1)\n",
    "            if value > best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "            alpha = max(alpha, best_value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return (best_value, best_move)\n",
    "    else:\n",
    "        best_value = float('inf')\n",
    "        for move in valid_moves:\n",
    "            new_game = game.copy()\n",
    "            new_game.make_move(move[0], move[1])\n",
    "            value, _ = alpha_beta_with_ordering(new_game, True, alpha, beta, depth + 1)\n",
    "            if value < best_value:\n",
    "                best_value = value\n",
    "                best_move = move\n",
    "            beta = min(beta, best_value)\n",
    "            if beta <= alpha:\n",
    "                break\n",
    "        return (best_value, best_move)\n",
    "\n",
    "# Compare with and without move ordering\n",
    "game = TicTacToe()\n",
    "\n",
    "alphabeta_nodes = 0\n",
    "start = time.time()\n",
    "value1, move1 = alpha_beta(game, True)\n",
    "time1 = time.time() - start\n",
    "nodes1 = alphabeta_nodes\n",
    "\n",
    "alphabeta_nodes = 0\n",
    "start = time.time()\n",
    "value2, move2 = alpha_beta_with_ordering(game, True)\n",
    "time2 = time.time() - start\n",
    "\n",
    "print(\"Move Ordering Impact:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Without ordering: {nodes1:,} nodes in {time1:.4f}s\")\n",
    "print(f\"With ordering:    {alphabeta_nodes:,} nodes in {time2:.4f}s\")\n",
    "print(f\"\\nImprovement: {(1 - alphabeta_nodes/nodes1)*100:.1f}% fewer nodes\")\n",
    "print(\"\\n💡 Good move ordering makes alpha-beta even more efficient!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "### Minimax\n",
    "- **Purpose**: Find optimal move assuming opponent plays optimally\n",
    "- **How**: Recursively build game tree, maximize at MAX nodes, minimize at MIN nodes\n",
    "- **Pros**: Guaranteed optimal (with perfect info)\n",
    "- **Cons**: Exponential time complexity O(b^d)\n",
    "\n",
    "### Alpha-Beta Pruning\n",
    "- **Purpose**: Speed up minimax without changing result\n",
    "- **How**: Prune branches that can't affect final decision\n",
    "- **Performance**: O(b^(d/2)) with good move ordering\n",
    "- **Result**: Same as minimax, just faster!\n",
    "\n",
    "### Move Ordering\n",
    "- Check better moves first\n",
    "- More pruning = faster search\n",
    "- Heuristics help (center/corners in TTT)\n",
    "\n",
    "### Real-World Limitations\n",
    "1. **Too many states**: Chess has ~10^120 positions\n",
    "2. **Solution**: Depth-limited search + evaluation function\n",
    "3. **Evaluation function**: Estimate game value without reaching end\n",
    "   - Example: Material count in chess (queen=9, rook=5, etc.)\n",
    "\n",
    "## Next Up\n",
    "\n",
    "In Lab 4, we'll explore:\n",
    "- Using professional libraries (NetworkX)\n",
    "- Real-world graph search\n",
    "- Advanced search techniques\n",
    "- Performance optimization\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "1. Implement Connect Four with minimax\n",
    "2. Add depth-limited search to handle larger games\n",
    "3. Create evaluation functions for partial game states\n",
    "4. Compare different move ordering strategies\n",
    "5. Implement iterative deepening (deeper search when time permits)\n",
    "6. Build a chess piece value evaluator\n",
    "\n",
    "Excellent work! You now understand how computers play games at superhuman levels! 🎮♟️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
