{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Bayes' Theorem and Inference\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- Understand and derive Bayes' theorem\n",
    "- Apply Bayesian inference to real problems\n",
    "- Build a naive Bayes classifier from scratch\n",
    "- Use pgmpy for probabilistic inference\n",
    "- Design systems that update beliefs with evidence\n",
    "\n",
    "## Why Bayes' Theorem?\n",
    "\n",
    "Bayes' theorem is the **foundation of probabilistic AI**. It tells us how to:\n",
    "- Update beliefs when we get new evidence\n",
    "- Reason backward from effects to causes\n",
    "- Make decisions under uncertainty\n",
    "\n",
    "**Real-world applications**:\n",
    "- üè• Medical diagnosis from symptoms\n",
    "- üìß Spam filtering from email content  \n",
    "- üîç Search engines ranking results\n",
    "- ü§ñ Robot localization from sensors\n",
    "- üí¨ Language understanding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Bayes' Theorem\n",
    "\n",
    "### The Formula\n",
    "\n",
    "$$P(H|E) = \\frac{P(E|H) \\cdot P(H)}{P(E)}$$\n",
    "\n",
    "Where:\n",
    "- **P(H|E)** = **Posterior**: Probability of hypothesis H given evidence E\n",
    "- **P(E|H)** = **Likelihood**: Probability of evidence E if hypothesis H is true\n",
    "- **P(H)** = **Prior**: Initial probability of hypothesis H\n",
    "- **P(E)** = **Evidence**: Total probability of evidence E (normalization constant)\n",
    "\n",
    "### Intuition\n",
    "\n",
    "Think of Bayes' theorem as **updating beliefs**:\n",
    "1. Start with a prior belief P(H)\n",
    "2. Observe evidence E\n",
    "3. Update to posterior belief P(H|E)\n",
    "\n",
    "### Derivation\n",
    "\n",
    "From conditional probability:\n",
    "- P(H|E) = P(H,E) / P(E)\n",
    "- P(E|H) = P(H,E) / P(H)\n",
    "- Therefore: P(H,E) = P(E|H) √ó P(H)\n",
    "- Substitute: P(H|E) = P(E|H) √ó P(H) / P(E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_theorem(prior: float, likelihood: float, evidence: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate posterior probability using Bayes' theorem.\n",
    "    \n",
    "    Args:\n",
    "        prior: P(H) - initial probability of hypothesis\n",
    "        likelihood: P(E|H) - probability of evidence given hypothesis\n",
    "        evidence: P(E) - total probability of evidence\n",
    "    \n",
    "    Returns:\n",
    "        posterior: P(H|E) - updated probability of hypothesis\n",
    "    \"\"\"\n",
    "    if evidence == 0:\n",
    "        raise ValueError(\"Evidence probability cannot be zero\")\n",
    "    \n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    return posterior\n",
    "\n",
    "\n",
    "def bayes_with_normalization(prior: float, likelihood: float, \n",
    "                            prior_complement: float, likelihood_complement: float) -> float:\n",
    "    \"\"\"\n",
    "    Calculate posterior using law of total probability for normalization.\n",
    "    \n",
    "    P(E) = P(E|H)¬∑P(H) + P(E|¬¨H)¬∑P(¬¨H)\n",
    "    \n",
    "    Args:\n",
    "        prior: P(H)\n",
    "        likelihood: P(E|H)\n",
    "        prior_complement: P(¬¨H)\n",
    "        likelihood_complement: P(E|¬¨H)\n",
    "    \n",
    "    Returns:\n",
    "        posterior: P(H|E)\n",
    "    \"\"\"\n",
    "    # Calculate evidence using law of total probability\n",
    "    evidence = likelihood * prior + likelihood_complement * prior_complement\n",
    "    \n",
    "    return bayes_theorem(prior, likelihood, evidence)\n",
    "\n",
    "\n",
    "# Example: Medical diagnosis revisited\n",
    "print(\"Medical Test Example with Bayes' Theorem\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Given information\n",
    "p_disease = 0.01  # 1% of population has disease (prior)\n",
    "p_test_pos_given_disease = 0.95  # 95% sensitivity (likelihood)\n",
    "p_test_pos_given_healthy = 0.05  # 5% false positive rate\n",
    "\n",
    "# Calculate P(disease | test positive)\n",
    "p_healthy = 1 - p_disease\n",
    "posterior = bayes_with_normalization(\n",
    "    prior=p_disease,\n",
    "    likelihood=p_test_pos_given_disease,\n",
    "    prior_complement=p_healthy,\n",
    "    likelihood_complement=p_test_pos_given_healthy\n",
    ")\n",
    "\n",
    "print(f\"Prior probability: P(disease) = {p_disease:.3f}\")\n",
    "print(f\"Likelihood: P(test+ | disease) = {p_test_pos_given_disease:.3f}\")\n",
    "print(f\"False positive rate: P(test+ | healthy) = {p_test_pos_given_healthy:.3f}\")\n",
    "print()\n",
    "print(f\"Posterior probability: P(disease | test+) = {posterior:.3f}\")\n",
    "print()\n",
    "print(f\"Interpretation: Even with a positive test, only {posterior*100:.1f}% chance of disease.\")\n",
    "print(f\"The prior matters! Disease is rare, so most positives are false positives.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Bayesian Updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bayesian_update(prior: float, likelihood: float, \n",
    "                             likelihood_complement: float, title: str = \"Bayesian Update\"):\n",
    "    \"\"\"\n",
    "    Visualize how Bayes' theorem updates beliefs.\n",
    "    \"\"\"\n",
    "    prior_complement = 1 - prior\n",
    "    \n",
    "    # Calculate posterior\n",
    "    posterior = bayes_with_normalization(\n",
    "        prior, likelihood, prior_complement, likelihood_complement\n",
    "    )\n",
    "    posterior_complement = 1 - posterior\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Prior distribution\n",
    "    categories = ['Hypothesis', '¬¨Hypothesis']\n",
    "    prior_probs = [prior, prior_complement]\n",
    "    colors = ['#3498db', '#e74c3c']\n",
    "    \n",
    "    bars1 = ax1.bar(categories, prior_probs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax1.set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Prior Beliefs (Before Evidence)', fontsize=13, fontweight='bold')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar, prob in zip(bars1, prior_probs):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{prob:.3f}', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Posterior distribution\n",
    "    posterior_probs = [posterior, posterior_complement]\n",
    "    bars2 = ax2.bar(categories, posterior_probs, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "    ax2.set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Posterior Beliefs (After Evidence)', fontsize=13, fontweight='bold')\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar, prob in zip(bars2, posterior_probs):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{prob:.3f}', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add change arrows\n",
    "    change = posterior - prior\n",
    "    change_pct = (change / prior * 100) if prior > 0 else 0\n",
    "    \n",
    "    fig.text(0.5, 0.02, \n",
    "            f'Evidence increases belief in hypothesis by {change_pct:.1f}%',\n",
    "            ha='center', fontsize=12, fontweight='bold',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize the medical test example\n",
    "visualize_bayesian_update(\n",
    "    prior=0.01,\n",
    "    likelihood=0.95,\n",
    "    likelihood_complement=0.05,\n",
    "    title=\"Medical Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Sequential Bayesian Updating\n",
    "\n",
    "One of the most powerful aspects of Bayesian reasoning is **sequential updating**.\n",
    "\n",
    "**Key insight**: Today's posterior becomes tomorrow's prior!\n",
    "\n",
    "When we get multiple pieces of evidence:\n",
    "1. Start with prior P(H)\n",
    "2. Update with evidence E‚ÇÅ ‚Üí get posterior P(H|E‚ÇÅ)\n",
    "3. Use P(H|E‚ÇÅ) as new prior\n",
    "4. Update with evidence E‚ÇÇ ‚Üí get P(H|E‚ÇÅ,E‚ÇÇ)\n",
    "5. Repeat...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianUpdater:\n",
    "    \"\"\"Track belief updates as evidence arrives.\"\"\"\n",
    "    \n",
    "    def __init__(self, prior: float, hypothesis_name: str = \"H\"):\n",
    "        \"\"\"\n",
    "        Initialize Bayesian updater.\n",
    "        \n",
    "        Args:\n",
    "            prior: Initial probability of hypothesis\n",
    "            hypothesis_name: Name of hypothesis for display\n",
    "        \"\"\"\n",
    "        self.current_belief = prior\n",
    "        self.hypothesis_name = hypothesis_name\n",
    "        self.history = [prior]\n",
    "        self.evidence_log = []\n",
    "    \n",
    "    def update(self, likelihood_if_true: float, likelihood_if_false: float, \n",
    "              evidence_name: str = \"Evidence\"):\n",
    "        \"\"\"\n",
    "        Update belief with new evidence.\n",
    "        \n",
    "        Args:\n",
    "            likelihood_if_true: P(E|H)\n",
    "            likelihood_if_false: P(E|¬¨H)\n",
    "            evidence_name: Description of evidence\n",
    "        \"\"\"\n",
    "        prior = self.current_belief\n",
    "        prior_complement = 1 - prior\n",
    "        \n",
    "        # Update using Bayes' theorem\n",
    "        posterior = bayes_with_normalization(\n",
    "            prior, likelihood_if_true,\n",
    "            prior_complement, likelihood_if_false\n",
    "        )\n",
    "        \n",
    "        self.current_belief = posterior\n",
    "        self.history.append(posterior)\n",
    "        self.evidence_log.append(evidence_name)\n",
    "        \n",
    "        return posterior\n",
    "    \n",
    "    def get_belief(self) -> float:\n",
    "        \"\"\"Get current belief.\"\"\"\n",
    "        return self.current_belief\n",
    "    \n",
    "    def plot_history(self):\n",
    "        \"\"\"Plot belief evolution over time.\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        steps = range(len(self.history))\n",
    "        plt.plot(steps, self.history, 'o-', linewidth=2, markersize=10, \n",
    "                color='#3498db', markeredgecolor='navy', markeredgewidth=2)\n",
    "        \n",
    "        # Add labels for each evidence\n",
    "        for i, evidence in enumerate(self.evidence_log, 1):\n",
    "            plt.annotate(evidence, \n",
    "                        xy=(i, self.history[i]), \n",
    "                        xytext=(10, 10),\n",
    "                        textcoords='offset points',\n",
    "                        ha='left',\n",
    "                        fontsize=9,\n",
    "                        bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5),\n",
    "                        arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "        \n",
    "        plt.xlabel('Evidence Step', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel(f'P({self.hypothesis_name})', fontsize=12, fontweight='bold')\n",
    "        plt.title(f'Bayesian Belief Updating for \"{self.hypothesis_name}\"', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"BayesianUpdater(belief={self.current_belief:.4f})\"\n",
    "\n",
    "\n",
    "# Example: Doctor diagnosing a patient\n",
    "print(\"Sequential Diagnosis Example\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Start with base rate of flu in population\n",
    "updater = BayesianUpdater(prior=0.05, hypothesis_name=\"Has Flu\")\n",
    "print(f\"Initial belief: P(Flu) = {updater.get_belief():.3f}\")\n",
    "print()\n",
    "\n",
    "# Evidence 1: Patient has fever\n",
    "# P(fever | flu) = 0.90, P(fever | no flu) = 0.10\n",
    "belief = updater.update(\n",
    "    likelihood_if_true=0.90,\n",
    "    likelihood_if_false=0.10,\n",
    "    evidence_name=\"Has Fever\"\n",
    ")\n",
    "print(f\"After observing fever: P(Flu | fever) = {belief:.3f}\")\n",
    "\n",
    "# Evidence 2: Patient has cough\n",
    "# P(cough | flu) = 0.85, P(cough | no flu) = 0.15\n",
    "belief = updater.update(\n",
    "    likelihood_if_true=0.85,\n",
    "    likelihood_if_false=0.15,\n",
    "    evidence_name=\"Has Cough\"\n",
    ")\n",
    "print(f\"After observing cough: P(Flu | fever, cough) = {belief:.3f}\")\n",
    "\n",
    "# Evidence 3: Rapid flu test positive\n",
    "# P(test+ | flu) = 0.95, P(test+ | no flu) = 0.05\n",
    "belief = updater.update(\n",
    "    likelihood_if_true=0.95,\n",
    "    likelihood_if_false=0.05,\n",
    "    evidence_name=\"Positive Flu Test\"\n",
    ")\n",
    "print(f\"After positive test: P(Flu | all evidence) = {belief:.3f}\")\n",
    "print()\n",
    "print(f\"Final diagnosis: {belief*100:.1f}% confident patient has flu\")\n",
    "\n",
    "# Visualize the updating process\n",
    "updater.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Naive Bayes Classifier\n",
    "\n",
    "### What is Naive Bayes?\n",
    "\n",
    "A **classification algorithm** based on Bayes' theorem with a \"naive\" independence assumption.\n",
    "\n",
    "**Goal**: Given features x‚ÇÅ, x‚ÇÇ, ..., x‚Çô, predict class C\n",
    "\n",
    "$$P(C|x_1,...,x_n) = \\frac{P(x_1,...,x_n|C) \\cdot P(C)}{P(x_1,...,x_n)}$$\n",
    "\n",
    "**Naive assumption**: Features are conditionally independent given the class.\n",
    "\n",
    "$$P(x_1,...,x_n|C) = P(x_1|C) \\cdot P(x_2|C) \\cdot ... \\cdot P(x_n|C)$$\n",
    "\n",
    "This simplifies computation dramatically!\n",
    "\n",
    "### Why \"Naive\"?\n",
    "\n",
    "Features are rarely truly independent (e.g., in spam detection, \"free\" and \"money\" often appear together).\n",
    "But surprisingly, **Naive Bayes works well even when the assumption is violated**!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    \"\"\"Naive Bayes classifier from scratch.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.class_priors = {}  # P(C)\n",
    "        self.feature_likelihoods = {}  # P(feature|C)\n",
    "        self.classes = []\n",
    "        self.features = []\n",
    "    \n",
    "    def fit(self, X: List[List], y: List):\n",
    "        \"\"\"\n",
    "        Train the classifier.\n",
    "        \n",
    "        Args:\n",
    "            X: List of feature lists (samples)\n",
    "            y: List of class labels\n",
    "        \"\"\"\n",
    "        n_samples = len(X)\n",
    "        self.classes = list(set(y))\n",
    "        \n",
    "        # Calculate class priors P(C)\n",
    "        class_counts = Counter(y)\n",
    "        for cls in self.classes:\n",
    "            self.class_priors[cls] = class_counts[cls] / n_samples\n",
    "        \n",
    "        # Calculate feature likelihoods P(feature|C)\n",
    "        self.feature_likelihoods = {cls: defaultdict(lambda: defaultdict(int)) \n",
    "                                   for cls in self.classes}\n",
    "        \n",
    "        # Count occurrences\n",
    "        for features, label in zip(X, y):\n",
    "            for feature_idx, feature_value in enumerate(features):\n",
    "                self.feature_likelihoods[label][feature_idx][feature_value] += 1\n",
    "        \n",
    "        # Convert counts to probabilities with Laplace smoothing\n",
    "        for cls in self.classes:\n",
    "            n_samples_class = class_counts[cls]\n",
    "            for feature_idx in self.feature_likelihoods[cls]:\n",
    "                n_unique_values = len(self.feature_likelihoods[cls][feature_idx])\n",
    "                for feature_value in self.feature_likelihoods[cls][feature_idx]:\n",
    "                    count = self.feature_likelihoods[cls][feature_idx][feature_value]\n",
    "                    # Laplace smoothing: add 1 to numerator and n_unique to denominator\n",
    "                    self.feature_likelihoods[cls][feature_idx][feature_value] = \\\n",
    "                        (count + 1) / (n_samples_class + n_unique_values)\n",
    "    \n",
    "    def predict_proba(self, features: List) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate probability for each class.\n",
    "        \n",
    "        Args:\n",
    "            features: List of feature values\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping class to probability\n",
    "        \"\"\"\n",
    "        posteriors = {}\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            # Start with prior\n",
    "            posterior = np.log(self.class_priors[cls])\n",
    "            \n",
    "            # Multiply by likelihoods (add in log space)\n",
    "            for feature_idx, feature_value in enumerate(features):\n",
    "                if feature_value in self.feature_likelihoods[cls][feature_idx]:\n",
    "                    likelihood = self.feature_likelihoods[cls][feature_idx][feature_value]\n",
    "                else:\n",
    "                    # Unseen feature value, use smoothing\n",
    "                    likelihood = 1e-6\n",
    "                posterior += np.log(likelihood)\n",
    "            \n",
    "            posteriors[cls] = posterior\n",
    "        \n",
    "        # Convert from log space and normalize\n",
    "        max_log_posterior = max(posteriors.values())\n",
    "        posteriors = {cls: np.exp(p - max_log_posterior) for cls, p in posteriors.items()}\n",
    "        total = sum(posteriors.values())\n",
    "        posteriors = {cls: p / total for cls, p in posteriors.items()}\n",
    "        \n",
    "        return posteriors\n",
    "    \n",
    "    def predict(self, features: List) -> str:\n",
    "        \"\"\"\n",
    "        Predict the most likely class.\n",
    "        \n",
    "        Args:\n",
    "            features: List of feature values\n",
    "        \n",
    "        Returns:\n",
    "            Predicted class\n",
    "        \"\"\"\n",
    "        posteriors = self.predict_proba(features)\n",
    "        return max(posteriors, key=posteriors.get)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"NaiveBayesClassifier(classes={self.classes})\"\n",
    "\n",
    "\n",
    "# Example: Simple spam classifier\n",
    "print(\"Spam Classifier Example\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training data: [has_word_free, has_word_money, has_word_meeting]\n",
    "X_train = [\n",
    "    [1, 1, 0],  # spam\n",
    "    [1, 1, 0],  # spam\n",
    "    [0, 1, 0],  # spam\n",
    "    [1, 0, 0],  # spam\n",
    "    [0, 0, 1],  # ham\n",
    "    [0, 0, 1],  # ham\n",
    "    [0, 0, 1],  # ham\n",
    "    [0, 1, 1],  # ham\n",
    "]\n",
    "\n",
    "y_train = ['spam', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham']\n",
    "\n",
    "# Train classifier\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Class priors:\")\n",
    "for cls, prob in nb.class_priors.items():\n",
    "    print(f\"  P({cls}) = {prob:.3f}\")\n",
    "\n",
    "# Test email: has \"free\" and \"money\", no \"meeting\"\n",
    "test_email = [1, 1, 0]\n",
    "print(\"\\nTest email features: [has_free=1, has_money=1, has_meeting=0]\")\n",
    "print()\n",
    "\n",
    "probs = nb.predict_proba(test_email)\n",
    "prediction = nb.predict(test_email)\n",
    "\n",
    "print(\"Posterior probabilities:\")\n",
    "for cls, prob in probs.items():\n",
    "    print(f\"  P({cls} | features) = {prob:.4f}\")\n",
    "\n",
    "print(f\"\\nPrediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Text Classification with Naive Bayes\n",
    "\n",
    "Let's build a more realistic text classifier that works with actual text documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNaiveBayes:\n",
    "    \"\"\"Naive Bayes for text classification.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.word_probs = {}  # P(word|class)\n",
    "        self.vocab = set()\n",
    "        self.classes = []\n",
    "    \n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"Simple tokenization: lowercase and split.\"\"\"\n",
    "        return text.lower().split()\n",
    "    \n",
    "    def fit(self, documents: List[str], labels: List[str]):\n",
    "        \"\"\"\n",
    "        Train on text documents.\n",
    "        \n",
    "        Args:\n",
    "            documents: List of text documents\n",
    "            labels: List of class labels\n",
    "        \"\"\"\n",
    "        self.classes = list(set(labels))\n",
    "        n_docs = len(documents)\n",
    "        \n",
    "        # Calculate class priors\n",
    "        class_counts = Counter(labels)\n",
    "        for cls in self.classes:\n",
    "            self.class_priors[cls] = class_counts[cls] / n_docs\n",
    "        \n",
    "        # Count words per class\n",
    "        word_counts = {cls: defaultdict(int) for cls in self.classes}\n",
    "        total_words = {cls: 0 for cls in self.classes}\n",
    "        \n",
    "        for doc, label in zip(documents, labels):\n",
    "            words = self.tokenize(doc)\n",
    "            self.vocab.update(words)\n",
    "            for word in words:\n",
    "                word_counts[label][word] += 1\n",
    "                total_words[label] += 1\n",
    "        \n",
    "        # Calculate word probabilities with Laplace smoothing\n",
    "        vocab_size = len(self.vocab)\n",
    "        for cls in self.classes:\n",
    "            self.word_probs[cls] = {}\n",
    "            for word in self.vocab:\n",
    "                count = word_counts[cls][word]\n",
    "                # Laplace smoothing\n",
    "                self.word_probs[cls][word] = (count + 1) / (total_words[cls] + vocab_size)\n",
    "    \n",
    "    def predict_proba(self, document: str) -> Dict[str, float]:\n",
    "        \"\"\"Calculate probability for each class.\"\"\"\n",
    "        words = self.tokenize(document)\n",
    "        posteriors = {}\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            # Start with log prior\n",
    "            log_posterior = np.log(self.class_priors[cls])\n",
    "            \n",
    "            # Add log likelihood for each word\n",
    "            for word in words:\n",
    "                if word in self.word_probs[cls]:\n",
    "                    log_posterior += np.log(self.word_probs[cls][word])\n",
    "                else:\n",
    "                    # Unknown word, use smoothing\n",
    "                    log_posterior += np.log(1 / (len(self.vocab) + 1))\n",
    "            \n",
    "            posteriors[cls] = log_posterior\n",
    "        \n",
    "        # Normalize\n",
    "        max_log = max(posteriors.values())\n",
    "        posteriors = {cls: np.exp(p - max_log) for cls, p in posteriors.items()}\n",
    "        total = sum(posteriors.values())\n",
    "        posteriors = {cls: p / total for cls, p in posteriors.items()}\n",
    "        \n",
    "        return posteriors\n",
    "    \n",
    "    def predict(self, document: str) -> str:\n",
    "        \"\"\"Predict class for document.\"\"\"\n",
    "        probs = self.predict_proba(document)\n",
    "        return max(probs, key=probs.get)\n",
    "\n",
    "\n",
    "# Example: Movie review sentiment analysis\n",
    "print(\"Movie Review Sentiment Analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training data\n",
    "train_reviews = [\n",
    "    \"this movie is amazing I loved it\",\n",
    "    \"great film wonderful acting\",\n",
    "    \"best movie ever so good\",\n",
    "    \"loved every minute fantastic\",\n",
    "    \"terrible movie waste of time\",\n",
    "    \"awful film so boring\",\n",
    "    \"worst movie ever horrible\",\n",
    "    \"hated it very bad\",\n",
    "]\n",
    "\n",
    "train_labels = ['positive', 'positive', 'positive', 'positive',\n",
    "                'negative', 'negative', 'negative', 'negative']\n",
    "\n",
    "# Train classifier\n",
    "text_nb = TextNaiveBayes()\n",
    "text_nb.fit(train_reviews, train_labels)\n",
    "\n",
    "print(f\"Vocabulary size: {len(text_nb.vocab)}\")\n",
    "print(f\"Classes: {text_nb.classes}\")\n",
    "print()\n",
    "\n",
    "# Test on new reviews\n",
    "test_reviews = [\n",
    "    \"this movie is great I loved it\",\n",
    "    \"terrible film very boring\",\n",
    "    \"amazing acting wonderful story\",\n",
    "]\n",
    "\n",
    "print(\"Test Reviews:\")\n",
    "print(\"=\" * 60)\n",
    "for review in test_reviews:\n",
    "    probs = text_nb.predict_proba(review)\n",
    "    prediction = text_nb.predict(review)\n",
    "    \n",
    "    print(f\"\\nReview: \\\"{review}\\\"\")\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "    print(f\"Confidence:\")\n",
    "    for cls, prob in probs.items():\n",
    "        print(f\"  {cls}: {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Using pgmpy for Bayesian Inference\n",
    "\n",
    "Now let's use the professional library **pgmpy** for more sophisticated probabilistic reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: pgmpy needs to be installed\n",
    "# pip install pgmpy\n",
    "\n",
    "try:\n",
    "    from pgmpy.factors.discrete import TabularCPD\n",
    "    from pgmpy.models import BayesianNetwork\n",
    "    from pgmpy.inference import VariableElimination\n",
    "    \n",
    "    PGMPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"pgmpy not installed. Run: pip install pgmpy\")\n",
    "    PGMPY_AVAILABLE = False\n",
    "\n",
    "if PGMPY_AVAILABLE:\n",
    "    # Create a simple Bayesian network\n",
    "    # Model: Rain ‚Üí Grass Wet\n",
    "    #       Sprinkler ‚Üí Grass Wet\n",
    "    \n",
    "    print(\"Bayesian Network with pgmpy\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Define network structure\n",
    "    model = BayesianNetwork([('Rain', 'GrassWet'), ('Sprinkler', 'GrassWet')])\n",
    "    \n",
    "    # Define CPDs (Conditional Probability Distributions)\n",
    "    cpd_rain = TabularCPD(variable='Rain', variable_card=2, values=[[0.7], [0.3]])\n",
    "    cpd_sprinkler = TabularCPD(variable='Sprinkler', variable_card=2, values=[[0.6], [0.4]])\n",
    "    \n",
    "    # P(GrassWet | Rain, Sprinkler)\n",
    "    cpd_grass = TabularCPD(\n",
    "        variable='GrassWet',\n",
    "        variable_card=2,\n",
    "        values=[\n",
    "            [0.99, 0.2, 0.1, 0.01],  # P(GrassWet=0 | ...)\n",
    "            [0.01, 0.8, 0.9, 0.99]   # P(GrassWet=1 | ...)\n",
    "        ],\n",
    "        evidence=['Rain', 'Sprinkler'],\n",
    "        evidence_card=[2, 2]\n",
    "    )\n",
    "    \n",
    "    # Add CPDs to model\n",
    "    model.add_cpds(cpd_rain, cpd_sprinkler, cpd_grass)\n",
    "    \n",
    "    # Check if model is valid\n",
    "    assert model.check_model()\n",
    "    print(\"Model is valid!\")\n",
    "    print()\n",
    "    \n",
    "    # Perform inference\n",
    "    inference = VariableElimination(model)\n",
    "    \n",
    "    # Query: What's P(Rain | GrassWet=1)?\n",
    "    result = inference.query(variables=['Rain'], evidence={'GrassWet': 1})\n",
    "    print(\"Query: P(Rain | Grass is wet)\")\n",
    "    print(result)\n",
    "    print()\n",
    "    \n",
    "    # Query: What's P(Sprinkler | GrassWet=1)?\n",
    "    result = inference.query(variables=['Sprinkler'], evidence={'GrassWet': 1})\n",
    "    print(\"Query: P(Sprinkler | Grass is wet)\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Drug Testing\n",
    "A drug test is 98% accurate (both sensitivity and specificity). Only 0.5% of the population uses the drug.\n",
    "If someone tests positive, what's the probability they actually use the drug?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate P(uses drug | positive test)\n",
    "# Your code here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Email Spam Filter\n",
    "Build a spam filter that uses word frequencies. Train on provided data and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build and evaluate spam filter\n",
    "# Your code here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Sequential Diagnosis\n",
    "Create a medical diagnosis system that updates beliefs as symptoms are reported.\n",
    "Use at least 3 symptoms and show the belief evolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build sequential diagnosis system\n",
    "# Your code here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Bayes' Theorem** - The foundation of probabilistic AI\n",
    "2. **Prior ‚Üí Posterior** - How evidence updates beliefs\n",
    "3. **Sequential updating** - Yesterday's posterior is today's prior\n",
    "4. **Naive Bayes** - Simple but powerful classification\n",
    "5. **Text classification** - Real-world NLP application\n",
    "6. **pgmpy** - Professional probabilistic programming\n",
    "\n",
    "### Why Bayes Matters\n",
    "\n",
    "- **Principled uncertainty**: Formal framework for reasoning\n",
    "- **Incorporates prior knowledge**: Use domain expertise\n",
    "- **Updates with evidence**: Learns from data\n",
    "- **Explains predictions**: Interpretable probabilities\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Lab 3, we'll learn about **Bayesian Networks** - powerful graphical models for complex reasoning!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
